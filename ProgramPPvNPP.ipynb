{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Pre-processing vs No pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "npp_data = pd.read_csv(\"diabetes_dataset.csv\")\n",
    "pp_data = pd.read_csv(\"diabetes_dataset_DONE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosed_diabetes                    1.000000\n",
       "hba1c                                 0.679397\n",
       "glucose_postprandial                  0.629832\n",
       "glucose_fasting                       0.510919\n",
       "diabetes_risk_score                   0.277300\n",
       "family_history_diabetes               0.197926\n",
       "age                                   0.137713\n",
       "bmi                                   0.097057\n",
       "systolic_bp                           0.095481\n",
       "waist_to_hip_ratio                    0.078918\n",
       "ldl_cholesterol                       0.067475\n",
       "cholesterol_total                     0.058173\n",
       "insulin_level                         0.057715\n",
       "triglycerides                         0.056230\n",
       "diastolic_bp                          0.035619\n",
       "cardiovascular_history                0.029793\n",
       "hypertension_history                  0.027524\n",
       "heart_rate                            0.022785\n",
       "screen_time_hours_per_day             0.018127\n",
       "alcohol_consumption_per_week          0.000760\n",
       "sleep_hours_per_day                  -0.000399\n",
       "diet_score                           -0.044298\n",
       "hdl_cholesterol                      -0.051227\n",
       "physical_activity_minutes_per_week   -0.100774\n",
       "Name: diagnosed_diabetes, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = npp_data.drop(\"diagnosed_diabetes\", axis=1)\n",
    "y = npp_data[\"diagnosed_diabetes\"]\n",
    "\n",
    "npp_data.corr(numeric_only=True)[\"diagnosed_diabetes\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_drop = [\n",
    "#     \"family_history_diabetes\",\n",
    "#     \"bmi\",\n",
    "#     \"cholesterol_total\",\n",
    "#     \"glucose_fasting\",\n",
    "#     \"glucose_postprandial\",\n",
    "#     \"diabetes_stage\"\n",
    "# ]\n",
    "\n",
    "# npp_data = npp_data.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X = npp_data.drop(\"diagnosed_diabetes\", axis=1)\n",
    "y = npp_data[\"diagnosed_diabetes\"]\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns\n",
    "X_num = X[num_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_num, y, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca  = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No pre-processing autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Wed Jul  5 22:17:35 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.97 GB / 16.00 GB (37.3%)\n",
      "Disk Space Avail:   785.63 GB / 926.35 GB (84.8%)\n",
      "===================================================\n",
      "Presets specified: ['medium']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP\"\n",
      "Train Data Rows:    70000\n",
      "Train Data Columns: 30\n",
      "Label Column:       diagnosed_diabetes\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6084.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 42.27 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  8 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', ...]\n",
      "\t\t('int', [])    : 15 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'family_history_diabetes', 'hypertension_history', ...]\n",
      "\t\t('object', []) :  7 | ['gender', 'ethnicity', 'education_level', 'income_level', 'employment_status', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  7 | ['gender', 'ethnicity', 'education_level', 'income_level', 'employment_status', ...]\n",
      "\t\t('float', [])     :  8 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', ...]\n",
      "\t\t('int', [])       : 12 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
      "\t0.2s = Fit runtime\n",
      "\t30 features in original data used to generate 30 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 11.35 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.03571428571428571, Train Rows: 67500, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.8 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.8 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.8 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t2.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.8 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.89s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.8 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.8 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.9 GB\n",
      "No improvement since epoch 0: early stopping\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t19.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.7 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t15.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.7 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesGini': 1.0}\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 45.47s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 90915.7 rows/s (2500 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2500 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "Deleting model LightGBMXT. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/LightGBMXT will be removed.\n",
      "Deleting model LightGBM. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/LightGBM will be removed.\n",
      "Deleting model RandomForestGini. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/RandomForestGini will be removed.\n",
      "Deleting model RandomForestEntr. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/RandomForestEntr will be removed.\n",
      "Deleting model CatBoost. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/CatBoost will be removed.\n",
      "Deleting model ExtraTreesEntr. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/ExtraTreesEntr will be removed.\n",
      "Deleting model NeuralNetFastAI. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/NeuralNetFastAI will be removed.\n",
      "Deleting model XGBoost. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/XGBoost will be removed.\n",
      "Deleting model NeuralNetTorch. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/NeuralNetTorch will be removed.\n",
      "Deleting model LightGBMLarge. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP/models/LightGBMLarge will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/NPP\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75721    0\n",
      "80184    1\n",
      "19864    0\n",
      "76699    0\n",
      "92991    1\n",
      "        ..\n",
      "42648    0\n",
      "86306    0\n",
      "45466    1\n",
      "63724    0\n",
      "34122    1\n",
      "Name: diagnosed_diabetes, Length: 30000, dtype: int64\n",
      "                 model  score_val eval_metric  pred_time_val  fit_time  \\\n",
      "0       ExtraTreesGini        1.0    accuracy       0.027197  1.006780   \n",
      "1  WeightedEnsemble_L2        1.0    accuracy       0.027498  1.044042   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.027197           1.006780            1       True   \n",
      "1                0.000301           0.037262            2       True   \n",
      "\n",
      "   fit_order  \n",
      "0          1  \n",
      "1          2  \n",
      "{'accuracy': 1.0, 'balanced_accuracy': 1.0, 'mcc': 1.0, 'roc_auc': 1.0, 'f1': 1.0, 'precision': 1.0, 'recall': 1.0}\n",
      "----------hiper-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'use_orig_features': False,\n",
       " 'valid_stacker': True,\n",
       " 'max_base_models': 0,\n",
       " 'max_base_models_per_type': 'auto',\n",
       " 'save_bag_folds': True,\n",
       " 'stratify': 'auto',\n",
       " 'bin': 'auto',\n",
       " 'n_bins': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(\n",
    "    npp_data,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_data = TabularDataset(train)\n",
    "\n",
    "predictor = TabularPredictor(label='diagnosed_diabetes', path='modelePPvsNPP/NPP').fit(train_data, presets=\"medium\", save_space=True, keep_only_best=True)\n",
    "\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "print(predictions)\n",
    "\n",
    "leaderboard = predictor.leaderboard()\n",
    "print(leaderboard)\n",
    "\n",
    "print(predictor.evaluate(train_data))\n",
    "\n",
    "\n",
    "\n",
    "print(\"----------hiper-----------\")\n",
    "\n",
    "model_name = predictor.model_best\n",
    "model_info = predictor.info()\n",
    "model_info['model_info'][model_name]['hyperparameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-processing autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Wed Jul  5 22:17:35 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.71 GB / 16.00 GB (35.7%)\n",
      "Disk Space Avail:   785.57 GB / 926.35 GB (84.8%)\n",
      "===================================================\n",
      "Presets specified: ['medium']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP\"\n",
      "Train Data Rows:    58080\n",
      "Train Data Columns: 16\n",
      "Label Column:       diagnosed_diabetes\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1.0, 0.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5829.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.09 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['age', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', ...]\n",
      "\t\t('int', [])   :  1 | ['Unnamed: 0']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['age', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', ...]\n",
      "\t\t('int', [])   :  1 | ['Unnamed: 0']\n",
      "\t0.0s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.09 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.043044077134986224, Train Rows: 55580, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.7 GB\n",
      "\t0.9032\t = Validation score   (accuracy)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.8 GB\n",
      "\t0.908\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.8 GB\n",
      "\t0.9068\t = Validation score   (accuracy)\n",
      "\t4.61s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.5 GB\n",
      "\t0.9064\t = Validation score   (accuracy)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.9068\t = Validation score   (accuracy)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.6 GB\n",
      "\t0.894\t = Validation score   (accuracy)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.5 GB\n",
      "\t0.8936\t = Validation score   (accuracy)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.6 GB\n",
      "\t0.9036\t = Validation score   (accuracy)\n",
      "\t19.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.9072\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.6 GB\n",
      "\t0.9044\t = Validation score   (accuracy)\n",
      "\t29.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.8 GB\n",
      "\t0.9072\t = Validation score   (accuracy)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t0.908\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 66.04s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2645247.2 rows/s (2500 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2500 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "Deleting model LightGBMXT. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/LightGBMXT will be removed.\n",
      "Deleting model RandomForestGini. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/RandomForestGini will be removed.\n",
      "Deleting model RandomForestEntr. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/RandomForestEntr will be removed.\n",
      "Deleting model CatBoost. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/CatBoost will be removed.\n",
      "Deleting model ExtraTreesGini. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/ExtraTreesGini will be removed.\n",
      "Deleting model ExtraTreesEntr. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/ExtraTreesEntr will be removed.\n",
      "Deleting model NeuralNetFastAI. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/NeuralNetFastAI will be removed.\n",
      "Deleting model XGBoost. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/XGBoost will be removed.\n",
      "Deleting model NeuralNetTorch. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/NeuralNetTorch will be removed.\n",
      "Deleting model LightGBMLarge. All files under /Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP/models/LightGBMLarge will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5/modelePPvsNPP/PP\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26892    1.0\n",
      "79545    0.0\n",
      "14554    0.0\n",
      "51734    1.0\n",
      "21371    1.0\n",
      "        ... \n",
      "43079    0.0\n",
      "26629    0.0\n",
      "40625    0.0\n",
      "29478    1.0\n",
      "17817    1.0\n",
      "Name: diagnosed_diabetes, Length: 24892, dtype: float64\n",
      "                 model  score_val eval_metric  pred_time_val  fit_time  \\\n",
      "0             LightGBM      0.908    accuracy       0.000649  0.421013   \n",
      "1  WeightedEnsemble_L2      0.908    accuracy       0.000945  0.459064   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.000649           0.421013            1       True   \n",
      "1                0.000296           0.038051            2       True   \n",
      "\n",
      "   fit_order  \n",
      "0          1  \n",
      "1          2  \n",
      "{'accuracy': 0.9115702479338843, 'balanced_accuracy': 0.9257947742338053, 'mcc': 0.8355979703444808, 'roc_auc': 0.9455088035049731, 'f1': 0.9200373657169547, 'precision': 0.9993911719939117, 'recall': 0.8523582864560796}\n",
      "----------hiper-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'use_orig_features': False,\n",
       " 'valid_stacker': True,\n",
       " 'max_base_models': 0,\n",
       " 'max_base_models_per_type': 'auto',\n",
       " 'save_bag_folds': True,\n",
       " 'stratify': 'auto',\n",
       " 'bin': 'auto',\n",
       " 'n_bins': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(\n",
    "    pp_data,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_data = TabularDataset(train)\n",
    "\n",
    "predictor = TabularPredictor(label='diagnosed_diabetes', path='modelePPvsNPP/PP').fit(train_data, presets=\"medium\", save_space=True, keep_only_best=True)\n",
    "\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "print(predictions)\n",
    "\n",
    "leaderboard = predictor.leaderboard()\n",
    "print(leaderboard)\n",
    "\n",
    "print(predictor.evaluate(train_data))\n",
    "\n",
    "\n",
    "\n",
    "print(\"----------hiper-----------\")\n",
    "\n",
    "model_name = predictor.model_best\n",
    "model_info = predictor.info()\n",
    "model_info['model_info'][model_name]['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
