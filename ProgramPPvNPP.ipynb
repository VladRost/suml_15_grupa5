{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Pre-processing vs No pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "npp_data = pd.read_csv(\"/Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5 08-41-28-896/diabetes_dataset.csv\")\n",
    "pp_data = pd.read_csv(\"/Users/ntix/Desktop/Programowanie/SUML/suml_15_grupa5 08-41-28-896/diabetes_dataset_DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosed_diabetes                    1.000000\n",
       "hba1c                                 0.679397\n",
       "glucose_postprandial                  0.629832\n",
       "glucose_fasting                       0.510919\n",
       "diabetes_risk_score                   0.277300\n",
       "family_history_diabetes               0.197926\n",
       "age                                   0.137713\n",
       "bmi                                   0.097057\n",
       "systolic_bp                           0.095481\n",
       "waist_to_hip_ratio                    0.078918\n",
       "ldl_cholesterol                       0.067475\n",
       "cholesterol_total                     0.058173\n",
       "insulin_level                         0.057715\n",
       "triglycerides                         0.056230\n",
       "diastolic_bp                          0.035619\n",
       "cardiovascular_history                0.029793\n",
       "hypertension_history                  0.027524\n",
       "heart_rate                            0.022785\n",
       "screen_time_hours_per_day             0.018127\n",
       "alcohol_consumption_per_week          0.000760\n",
       "sleep_hours_per_day                  -0.000399\n",
       "diet_score                           -0.044298\n",
       "hdl_cholesterol                      -0.051227\n",
       "physical_activity_minutes_per_week   -0.100774\n",
       "Name: diagnosed_diabetes, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = npp_data.drop(\"diagnosed_diabetes\", axis=1)\n",
    "y = npp_data[\"diagnosed_diabetes\"]\n",
    "\n",
    "npp_data.corr(numeric_only=True)[\"diagnosed_diabetes\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_drop = [\n",
    "#     \"family_history_diabetes\",\n",
    "#     \"bmi\",\n",
    "#     \"cholesterol_total\",\n",
    "#     \"glucose_fasting\",\n",
    "#     \"glucose_postprandial\",\n",
    "#     \"diabetes_stage\"\n",
    "# ]\n",
    "\n",
    "# npp_data = npp_data.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Male'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5y/_90dcxjn6hj56_b213kfnp8w0000gn/T/ipykernel_18603/2876871441.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_train_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mX_test_pca\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mFortran\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mTo\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0mit\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \"\"\"\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_is_centered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mU\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# written in a way to avoid the need for any inplace modification of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# the input data contrary to the other solvers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# The copy will happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# later, only if needed, once the solver negotiation below is done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2940\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1052\u001b[0m                         )\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n\u001b[1;32m   1058\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         if (\n\u001b[1;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Male'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X = npp_data.drop(\"diagnosed_diabetes\", axis=1)\n",
    "y = npp_data[\"diagnosed_diabetes\"]\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns\n",
    "X_num = X[num_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_num, y, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca  = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No pre-processing autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"modelePPvsNPP/NPP\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Wed Jul  5 22:17:35 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.47 GB / 16.00 GB (34.2%)\n",
      "Disk Space Avail:   786.66 GB / 926.35 GB (84.9%)\n",
      "===================================================\n",
      "Presets specified: ['medium']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/ntix/Desktop/Programowanie/SUML/AutoGluon/modelePPvsNPP/NPP\"\n",
      "Train Data Rows:    70000\n",
      "Train Data Columns: 24\n",
      "Label Column:       diagnosed_diabetes\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5615.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 35.24 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  7 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'waist_to_hip_ratio', 'insulin_level', ...]\n",
      "\t\t('int', [])    : 11 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'hypertension_history', 'cardiovascular_history', ...]\n",
      "\t\t('object', []) :  6 | ['gender', 'ethnicity', 'education_level', 'income_level', 'employment_status', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['gender', 'ethnicity', 'education_level', 'income_level', 'employment_status', ...]\n",
      "\t\t('float', [])     : 7 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'waist_to_hip_ratio', 'insulin_level', ...]\n",
      "\t\t('int', [])       : 9 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['hypertension_history', 'cardiovascular_history']\n",
      "\t0.1s = Fit runtime\n",
      "\t24 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.08 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.03571428571428571, Train Rows: 67500, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.5 GB\n",
      "\t0.8996\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.4 GB\n",
      "\t0.9112\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.4 GB\n",
      "\t0.9104\t = Validation score   (accuracy)\n",
      "\t3.74s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.3 GB\n",
      "\t0.9104\t = Validation score   (accuracy)\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.9104\t = Validation score   (accuracy)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.5 GB\n",
      "\t0.8816\t = Validation score   (accuracy)\n",
      "\t1.98s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.6 GB\n",
      "\t0.8804\t = Validation score   (accuracy)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.6 GB\n",
      "\t0.9068\t = Validation score   (accuracy)\n",
      "\t26.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.9108\t = Validation score   (accuracy)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.5 GB\n",
      "\t0.9052\t = Validation score   (accuracy)\n",
      "\t28.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.2 GB\n",
      "\t0.91\t = Validation score   (accuracy)\n",
      "\t2.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t0.9112\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 72.85s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1453529.2 rows/s (2500 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2500 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/ntix/Desktop/Programowanie/SUML/AutoGluon/modelePPvsNPP/NPP\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75721    0\n",
      "80184    1\n",
      "19864    0\n",
      "76699    0\n",
      "92991    0\n",
      "        ..\n",
      "42648    0\n",
      "86306    0\n",
      "45466    1\n",
      "63724    0\n",
      "34122    1\n",
      "Name: diagnosed_diabetes, Length: 30000, dtype: int64\n",
      "                  model  score_val eval_metric  pred_time_val   fit_time  \\\n",
      "0              LightGBM     0.9112    accuracy       0.001441   0.422177   \n",
      "1   WeightedEnsemble_L2     0.9112    accuracy       0.001720   0.459363   \n",
      "2               XGBoost     0.9108    accuracy       0.004410   0.382813   \n",
      "3              CatBoost     0.9104    accuracy       0.001519   0.992072   \n",
      "4      RandomForestGini     0.9104    accuracy       0.040633   3.738437   \n",
      "5      RandomForestEntr     0.9104    accuracy       0.040752   3.748685   \n",
      "6         LightGBMLarge     0.9100    accuracy       0.003547   2.315887   \n",
      "7       NeuralNetFastAI     0.9068    accuracy       0.012079  26.660343   \n",
      "8        NeuralNetTorch     0.9052    accuracy       0.010133  28.542751   \n",
      "9            LightGBMXT     0.8996    accuracy       0.003243   0.777752   \n",
      "10       ExtraTreesGini     0.8816    accuracy       0.061521   1.984434   \n",
      "11       ExtraTreesEntr     0.8804    accuracy       0.061148   2.061756   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.001441           0.422177            1       True   \n",
      "1                 0.000279           0.037186            2       True   \n",
      "2                 0.004410           0.382813            1       True   \n",
      "3                 0.001519           0.992072            1       True   \n",
      "4                 0.040633           3.738437            1       True   \n",
      "5                 0.040752           3.748685            1       True   \n",
      "6                 0.003547           2.315887            1       True   \n",
      "7                 0.012079          26.660343            1       True   \n",
      "8                 0.010133          28.542751            1       True   \n",
      "9                 0.003243           0.777752            1       True   \n",
      "10                0.061521           1.984434            1       True   \n",
      "11                0.061148           2.061756            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0           2  \n",
      "1          12  \n",
      "2           9  \n",
      "3           5  \n",
      "4           3  \n",
      "5           4  \n",
      "6          11  \n",
      "7           8  \n",
      "8          10  \n",
      "9           1  \n",
      "10          6  \n",
      "11          7  \n",
      "{'accuracy': 0.9129, 'balanced_accuracy': 0.9271740971419724, 'mcc': 0.837164512041939, 'roc_auc': 0.9462556254670005, 'f1': 0.9219843636037927, 'precision': 0.9983650169040625, 'recall': 0.8564602401046}\n",
      "----------hiper-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'use_orig_features': False,\n",
       " 'valid_stacker': True,\n",
       " 'max_base_models': 0,\n",
       " 'max_base_models_per_type': 'auto',\n",
       " 'save_bag_folds': True,\n",
       " 'stratify': 'auto',\n",
       " 'bin': 'auto',\n",
       " 'n_bins': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(\n",
    "    npp_data,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_data = TabularDataset(train)\n",
    "\n",
    "predictor = TabularPredictor(label='diagnosed_diabetes', path='modelePPvsNPP/NPP').fit(train_data, presets=\"medium\")\n",
    "\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "print(predictions)\n",
    "\n",
    "leaderboard = predictor.leaderboard()\n",
    "print(leaderboard)\n",
    "\n",
    "print(predictor.evaluate(train_data))\n",
    "\n",
    "\n",
    "\n",
    "print(\"----------hiper-----------\")\n",
    "\n",
    "model_name = predictor.model_best\n",
    "model_info = predictor.info()\n",
    "model_info['model_info'][model_name]['hyperparameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-processing autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"modelePPvsNPP/NPP\"\n",
      "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Wed Jul  5 22:17:35 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       4.83 GB / 16.00 GB (30.2%)\n",
      "Disk Space Avail:   785.72 GB / 926.35 GB (84.8%)\n",
      "===================================================\n",
      "Presets specified: ['medium']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/ntix/Desktop/Programowanie/SUML/AutoGluon/modelePPvsNPP/NPP\"\n",
      "Train Data Rows:    58080\n",
      "Train Data Columns: 16\n",
      "Label Column:       diagnosed_diabetes\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1.0, 0.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4994.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.09 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['age', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', ...]\n",
      "\t\t('int', [])   :  1 | ['Unnamed: 0']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['age', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', ...]\n",
      "\t\t('int', [])   :  1 | ['Unnamed: 0']\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.09 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.043044077134986224, Train Rows: 55580, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/4.8 GB\n",
      "\t0.9032\t = Validation score   (accuracy)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/4.8 GB\n",
      "\t0.908\t = Validation score   (accuracy)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/4.8 GB\n",
      "\t0.9068\t = Validation score   (accuracy)\n",
      "\t3.83s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.0 GB\n",
      "\t0.9064\t = Validation score   (accuracy)\n",
      "\t4.22s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.9068\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/4.9 GB\n",
      "\t0.894\t = Validation score   (accuracy)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/5.1 GB\n",
      "\t0.8936\t = Validation score   (accuracy)\n",
      "\t1.61s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.0 GB\n",
      "\t0.9036\t = Validation score   (accuracy)\n",
      "\t21.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.9072\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/4.9 GB\n",
      "\t0.9044\t = Validation score   (accuracy)\n",
      "\t29.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/5.1 GB\n",
      "\t0.9072\t = Validation score   (accuracy)\n",
      "\t1.65s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t0.908\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 66.78s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2685213.8 rows/s (2500 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2500 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/ntix/Desktop/Programowanie/SUML/AutoGluon/modelePPvsNPP/NPP\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26892    1.0\n",
      "79545    0.0\n",
      "14554    0.0\n",
      "51734    1.0\n",
      "21371    1.0\n",
      "        ... \n",
      "43079    0.0\n",
      "26629    0.0\n",
      "40625    0.0\n",
      "29478    1.0\n",
      "17817    1.0\n",
      "Name: diagnosed_diabetes, Length: 24892, dtype: float64\n",
      "                  model  score_val eval_metric  pred_time_val   fit_time  \\\n",
      "0              LightGBM     0.9080    accuracy       0.000629   0.397942   \n",
      "1   WeightedEnsemble_L2     0.9080    accuracy       0.000931   0.435572   \n",
      "2               XGBoost     0.9072    accuracy       0.001741   0.171319   \n",
      "3         LightGBMLarge     0.9072    accuracy       0.002077   1.654974   \n",
      "4              CatBoost     0.9068    accuracy       0.000329   0.287794   \n",
      "5      RandomForestGini     0.9068    accuracy       0.037434   3.832963   \n",
      "6      RandomForestEntr     0.9064    accuracy       0.039479   4.223098   \n",
      "7        NeuralNetTorch     0.9044    accuracy       0.005798  29.869092   \n",
      "8       NeuralNetFastAI     0.9036    accuracy       0.011221  21.266528   \n",
      "9            LightGBMXT     0.9032    accuracy       0.005518   1.046531   \n",
      "10       ExtraTreesGini     0.8940    accuracy       0.050802   1.517527   \n",
      "11       ExtraTreesEntr     0.8936    accuracy       0.047864   1.608659   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000629           0.397942            1       True   \n",
      "1                 0.000302           0.037630            2       True   \n",
      "2                 0.001741           0.171319            1       True   \n",
      "3                 0.002077           1.654974            1       True   \n",
      "4                 0.000329           0.287794            1       True   \n",
      "5                 0.037434           3.832963            1       True   \n",
      "6                 0.039479           4.223098            1       True   \n",
      "7                 0.005798          29.869092            1       True   \n",
      "8                 0.011221          21.266528            1       True   \n",
      "9                 0.005518           1.046531            1       True   \n",
      "10                0.050802           1.517527            1       True   \n",
      "11                0.047864           1.608659            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0           2  \n",
      "1          12  \n",
      "2           9  \n",
      "3          11  \n",
      "4           5  \n",
      "5           3  \n",
      "6           4  \n",
      "7          10  \n",
      "8           8  \n",
      "9           1  \n",
      "10          6  \n",
      "11          7  \n",
      "{'accuracy': 0.9115702479338843, 'balanced_accuracy': 0.9257947742338053, 'mcc': 0.8355979703444808, 'roc_auc': 0.9455088035049731, 'f1': 0.9200373657169547, 'precision': 0.9993911719939117, 'recall': 0.8523582864560796}\n",
      "----------hiper-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'use_orig_features': False,\n",
       " 'valid_stacker': True,\n",
       " 'max_base_models': 0,\n",
       " 'max_base_models_per_type': 'auto',\n",
       " 'save_bag_folds': True,\n",
       " 'stratify': 'auto',\n",
       " 'bin': 'auto',\n",
       " 'n_bins': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(\n",
    "    pp_data,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_data = TabularDataset(train)\n",
    "\n",
    "predictor = TabularPredictor(label='diagnosed_diabetes', path='modelePPvsNPP/NPP').fit(train_data, presets=\"medium\")\n",
    "\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "print(predictions)\n",
    "\n",
    "leaderboard = predictor.leaderboard()\n",
    "print(leaderboard)\n",
    "\n",
    "print(predictor.evaluate(train_data))\n",
    "\n",
    "\n",
    "\n",
    "print(\"----------hiper-----------\")\n",
    "\n",
    "model_name = predictor.model_best\n",
    "model_info = predictor.info()\n",
    "model_info['model_info'][model_name]['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
